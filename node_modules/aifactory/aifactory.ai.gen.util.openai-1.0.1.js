/*
	AI factory | OPENAI
*/

var entityos = require('entityos')
var _ = require('lodash')
var moment = require('moment');

module.exports = 
{
	VERSION: '1.0.0',

	init: function (param)
	{
		
		// Using Agent SDK
		// Responses API
		// https://platform.openai.com/docs/libraries
		// https://cookbook.openai.com/examples/file_search_responses
		// /DEV.md file in this repo.

		entityos.add(
		{
			name: 'ai-gen-util-chat',
			code: function (param)
			{
				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');

				let keyPath = _.get(aiSettings, 'service.keypath');

				let apiKey = _.get(settings, keyPath);
                const OpenAI = require("openai");

                const openai = new OpenAI(
                {
                    apiKey: apiKey
                });

				const maxTokensDefault = _.get(settings, 'ai.defaults.maxtokens', 1000);
				const temperatureDefault = _.get(settings, 'ai.defaults.temperature', 0.7);

				const maxTokens = _.get(param, 'maxTokens', maxTokensDefault);
				const temperature = _.get(param, 'temperature', temperatureDefault);

				function generateText(param)
				{
					openai.chat.completions.create({
						model: param.model,
						messages: [
							{ role: 'system', content: param.messages.system },
							{ role: 'user', content: param.messages.user }
						],
						max_tokens: maxTokens,
						temperature: temperature
					})
					.then(function (completion)
					{
						_.set(param, 'messages.response', completion.choices[0]?.message?.content);

						if (_.get(param, 'onComplete') != undefined)
						{
							entityos._util.onComplete(param);
						}
						else
						{
							entityos.invoke('util-end', param);
						}
					})
					.catch(function (responseError)
					{
						_.set(param, 'messages.response',  '!!: ' + _.get(responseError, 'error.message'));

						if (_.get(param, 'onComplete') != undefined)
						{
							entityos._util.onComplete(param);
						}
						else
						{
							entityos.invoke('util-end', param);
						}

						//entityos.invoke('util-end', {error: _.get(responseError, 'error.message')});
					});
				}

				let messages = _.get(param, 'messages', {});

				if (messages.system == undefined)
				{
					messages.system = _.get(aiSettings, 'ai.defaults.messages.system');
				}

                if (messages == undefined)
                {
                    entityos.invoke('util-end', {error: 'No messages!'});
                }
                else
                {
					generateText(
					{
						messages: messages,
						model: aiSettings.model.name,
						onComplete: param.onComplete
					});
                }
			}
		});

		entityos.add(
		{
			name: 'ai-gen-util-chat-openai-completion',
			code: function (param)
			{
                // https://platform.openai.com
                // https://platform.openai.com/docs/api-reference
                // https://github.com/openai/openai-node/blob/master/examples/demo.ts

				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');

				let keyPath = _.get(aiSettings, 'service.keypath');

				let apiKey = _.get(settings, keyPath);
                const OpenAI = require("openai");

                const openai = new OpenAI(
                {
                    apiKey: apiKey
                });

				console.log('model:' + aiSettings.model.name)

                async function generateText(param)
                {
                    const completion = await openai.chat.completions.create(
                    {
                        model: param.model,
                        messages:
                        [
                            { role: 'system', content: param.messages.system },
                            { role: 'user', content: param.messages.user }
                        ],
                        max_tokens: 1000,
                        temperature: 0.7
                    });

                    _.set(param, 'messages.response', completion.choices[0]?.message?.content);

                    if (_.get(param, 'onComplete') != undefined)
                    {
                        entityos._util.onComplete(param)
                    }
                    else
                    {
                        entityos.invoke('util-end', param);
                    }
                }

				let messages = _.get(param, 'messages', {});

				if (messages.system == undefined)
				{
					messages.system = _.get(aiSettings, 'ai.defaults.messages.system');
				}

                if (messages == undefined)
                {
                    entityos.invoke('util-end', {error: 'No messages!'});
                }
                else
                {
					generateText(
					{
						messages: messages,
						model: aiSettings.model.name,
						onComplete: param.onComplete
					});
                }
			}
		});

		entityos.add(
		{
			name: 'ai-gen-util-service-models',
			code: function (param)
			{
				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');
				
				if (aiSettings == undefined)
				{
					aiSettings = entityos.invoke('ai-gen-util-get-settings');
				}

				console.log(aiSettings)

				let keyPath = _.get(aiSettings, 'service.keypath');
				let apiKey = _.get(settings, keyPath);

                const OpenAI = require("openai");

                const openai = new OpenAI(
                {
                    apiKey: apiKey
                });

				openai.models.list()
				.then(function(response)
				{
					let models = response.data;
					_.each(models, function (model)
					{
						model.isChat = (model.id.startsWith("gpt-") || model.id.includes("chat"))
					});

					const modelsChat = _.filter(models, function (model) {return model.isChat});
					const modelsChatSimple = _.filter(models, function (model) {return (model.isChat && _.split(model.id, '-').length <= 3)})

					console.log(models);

					_.set(param, 'models', models);
					_.set(param, 'modelsChat', modelsChat);
					_.set(param, 'modelsChatSimple', modelsChatSimple);

					if (_.get(param, 'onComplete') != undefined)
					{
						entityos._util.onComplete(param)
					}
					else
					{
						entityos.invoke('util-end', {data:
						{
							models: models,
							modelsChat: modelsChat,
							modelsChatSimple: modelsChatSimple
						}});
					}
				})
				.catch(function(err)
				{
					console.error("Error listing models:", err);
				});
			}
		});
	}
}