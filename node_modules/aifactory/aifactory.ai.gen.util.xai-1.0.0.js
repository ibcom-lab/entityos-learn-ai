/*
	AI factory | X.AI
	USES OPENAI LIBRARY
	Default model: grok-3-mini-beta
	https://x.ai/api

	Direct https request:

	curl https://api.x.ai/v1/chat/completions \
		-H "Content-Type: application/json" \
		-H "Authorization: Bearer xai-uDclYK1cili0u3MbcX7ulgzIZjCYzbwWzjpTKHSG4ppKlzVqLhicTy05Eafgwl2xhiBYFlnJzF7wJMVH" \
		-d '{
		"messages": [
			{
			"role": "system",
			"content": "You are a test assistant."
			},
			{
			"role": "user",
			"content": "Testing. Just say hi and hello world and nothing else."
			}
		],
		"model": "grok-3-latest",
		"stream": false,
		"temperature": 0
}'
*/

var entityos = require('entityos')
var _ = require('lodash')
var moment = require('moment');

module.exports = 
{
	VERSION: '1.0.0',

	init: function (param)
	{
		entityos.add(
		{
			name: 'ai-gen-util-chat',
			code: function (param)
			{
				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');

				let keyPath = _.get(aiSettings, 'service.keypath');

				let apiKey = _.get(settings, keyPath);
				const apiBaseURL = 'https://'
					+ _.get(aiSettings, 'service.host.name', 'api.x.ai')
					+ _.get(aiSettings, 'service.host.basePath', '/v1');

                const OpenAI = require("openai");

                const xai = new OpenAI(
                {
                    apiKey: apiKey,
					baseURL: apiBaseURL
                });

                async function generateText(param)
                {
                    const completion = await xai.chat.completions.create(
                    {
                        model: param.model,
                        messages:
                        [
                            { role: 'system', content: param.messages.system },
                            { role: 'user', content: param.messages.user }
                        ],
                        max_tokens: 1000,
                        temperature: 0.7
                    });

                    _.set(param, 'messages.response', completion.choices[0]?.message?.content);

                    if (_.get(param, 'onComplete') != undefined)
                    {
                        entityos._util.onComplete(param)
                    }
                    else
                    {
                        entityos.invoke('util-end', param);
                    }
                }

				let messages = _.get(param, 'messages', {});

				if (messages.system == undefined)
				{
					messages.system = _.get(aiSettings, 'ai.defaults.messages.system');
				}

                if (messages == undefined)
                {
                    entityos.invoke('util-end', {error: 'No messages!'});
                }
                else
                {
					generateText(
					{
						messages: messages,
						model: aiSettings.model.name,
						onComplete: param.onComplete
					});
                }
			}
		});

		entityos.add(
		{
			name: 'ai-gen-util-chat-openai-completion',
			code: function (param)
			{
                // https://platform.openai.com
                // https://platform.openai.com/docs/api-reference
                // https://github.com/openai/openai-node/blob/master/examples/demo.ts

				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');

				let keyPath = _.get(aiSettings, 'service.keypath');

				let apiKey = _.get(settings, keyPath);
                const OpenAI = require("openai");

                const openai = new OpenAI(
                {
                    apiKey: apiKey
                });

				console.log('model:' + aiSettings.model.name)

                async function generateText(param)
                {
                    const completion = await openai.chat.completions.create(
                    {
                        model: param.model,
                        messages:
                        [
                            { role: 'system', content: param.messages.system },
                            { role: 'user', content: param.messages.user }
                        ],
                        max_tokens: 1000,
                        temperature: 0.7
                    });

                    _.set(param, 'messages.response', completion.choices[0]?.message?.content);

                    if (_.get(param, 'onComplete') != undefined)
                    {
                        entityos._util.onComplete(param)
                    }
                    else
                    {
                        entityos.invoke('util-end', param);
                    }
                }

				let messages = _.get(param, 'messages', {});

				if (messages.system == undefined)
				{
					messages.system = _.get(aiSettings, 'ai.defaults.messages.system');
				}

                if (messages == undefined)
                {
                    entityos.invoke('util-end', {error: 'No messages!'});
                }
                else
                {
					generateText(
					{
						messages: messages,
						model: aiSettings.model.name,
						onComplete: param.onComplete
					});
                }
			}
		});

		entityos.add(
		{
			name: 'ai-gen-util-service-models',
			code: function (param)
			{
				const settings = entityos.get({scope: '_settings'});
                let aiSettings = _.get(param, 'settings');
				
				if (aiSettings == undefined)
				{
					aiSettings = entityos.invoke('ai-gen-util-get-settings');
				}

				console.log(aiSettings)

				let keyPath = _.get(aiSettings, 'service.keypath');
				let apiKey = _.get(settings, keyPath);

                const OpenAI = require("openai");

                const openai = new OpenAI(
                {
                    apiKey: apiKey
                });

				openai.models.list()
				.then(function(response)
				{
					let models = response.data;
					_.each(models, function (model)
					{
						model.isChat = (model.id.startsWith("gpt-") || model.id.includes("chat"))
					});

					//console.log(models);

					_.set(param, 'models', models);
					_.set(param, 'modelsChat', _.filter(models, function (model) {return model.isChat} ))
					_.set(param, 'modelsChatSimple', _.filter(models, function (model) {return (model.isChat && _.split(model.id, '-').length <= 3)}))

					if (_.get(param, 'onComplete') != undefined)
					{
						entityos._util.onComplete(param)
					}
					else
					{
						entityos.invoke('util-end', param);
					}
				})
				.catch(function(err)
				{
					console.error("Error listing models:", err);
				});
			}
		});
	}
}